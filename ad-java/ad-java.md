# Java进阶——分布式架构

## 消息队列

### 核心问题

- #### 为什么要使用消息队列？

  - 解耦

    通过接口调用是强耦合性的，为不同的消息发送要调用不同的接口。

    如果使用MQ，消息的生产者只需要考虑把消息送进队列，消费者只需要从队列消费消息。

    通过MQ，Pub/Sub发布订阅消息模型，实现消息生产者系统和消费者系统解耦。

  - 异步

    消息生产者不需要阻塞等待消费者，缩短响应时间。（有可能造成消息被积压）

  - 削峰

    高峰期容忍消息挤压，平峰期慢慢消费消息。

    避免下层系统被打死。

- #### 消息队列的优缺点？

  - 系统可用性降低

    MQ存在单点问题，加入MQ挂了会导致整个系统故障。

  - 系统复杂度提高

    如何保证以下一堆问题。

  - 一致性问题

    比如BCD三个系统消费，BC写库成功，C失败，导致数据不一致

- #### Kafka, ActiveMQ, RabbitMQ, RocketMQ 都有什么区别？、

  | 特性                      | ActiveMQ               | RabbitMQ                                         | RocketMQ                                                     | Kafka                                                        |
  | ------------------------- | ---------------------- | ------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | 单机吞吐量                | 万级                   | 万级                                             | 10万级                                                       | 10万级，一般配合大数据类的系统来进行实时数据计算、日志采集等场景。 |
  | topic数量对于吞吐量的影响 |                        |                                                  | topic可以达到几百/几千的级别，吞吐量**小幅下降**。RocketMQ的一大优势，在同等机器下支撑大量topic。 | topic从几十到几百个的时候，吞吐量会**大幅度下降**。在同等机器下，kafka需要保证topic数量不要过多，如果要支撑大量topic，需要增加机器资源。 |
  | 时效性                    | 毫秒级                 | 微秒级                                           | 毫秒级                                                       | 毫秒级                                                       |
  | 可用性                    | 高，主从架构实现高可用 | 高，主从架构实现高可用                           | 非常高，分布式架构                                           | 非常高，分布式，一个数据多个副本，少量机器宕机不会丢失数据   |
  | 消息可靠性                | 有较低概率丢失         | 基本不丢失                                       | 经过参数优化可以做到0丢失                                    | 经过参数优化可以做到0丢失                                    |
  | 功能支持                  | MQ领域的功能极其完备   | 基于erlang开发，并发能力很强，性能极好，延时很低 | MQ功能较为完善，分布式拓展性高                               | 功能比较简单，主要支撑简单MQ功能，在大数据实时计算以及日志采集被大规模使用 |

- #### 如何保证消息队列的高可用？

  ##### RabbitMQ的高可用

  RabbitMQ是基于主从做高可用的

  - 单机模式

  - 普通集群模式

    在这个模式中，部署的队列只会被放在一个实例中，其他实例只有队列的元数据，假如从另一个实例拉取数据，这个实例会去从这个队列所在的实例拉取数据。

    从随机实例拉取数据：数据拉取开销

    从主实例拉取数据：单实例性能瓶颈

  - 镜像集群模式（高可用）

    在这个模式中，部署的队列的元数据和实际数据会被同步到所有节点。

    好处：高可用

    坏处：性能开销极大，没有办法线性拓展高负载的队列。

  ##### Kafka的高可用性

  Kafka的架构：由多个broker组成，每个broker是一个节点；创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上。

  RabbitMQ之流并不算是分布式消息队列，一个队列始终只能存在一个节点上，要么就是完整镜像到另一个节点。

  Kafka 0.8之前也是没有高可用机制的，一个broker宕机会导致所存的partition不可读写。

  Kafka 0.8之后提供了一个replica机制。每个partition的数据都会同步到其他机器上，形成自己的多个副本。所有replica会选出一个leader，其他的replica是follower，消费者之会跟leader打交道，读直接读leader的数据，写会被leader同步到follower上。

  只有leader可读写？

  如果任何一个replica都可以读写，那就要考虑数据一致性问题，导致系统复杂度过高，容错性降低。

  **高可用：**某个broker宕机了存在备份冗余，leader down了重新选举leader，follower down了就down了。

  **写数据：**生产者只写给leader，leader先落地本地磁盘。接着其他follower主动来pull数据，一旦follower同步完成，就会发送ack给leader。leader收到所有ack之后，返回操作成功给生产者。

  **读数据：**消费者只从leader读取，但是只有这个消息被所有follower同步成功返回ack之后，才能被消费者读取到。

- #### 如何保证消息不被重复消费？如何保证消费的时候是幂等的？

  ##### 保证消息不被重复消费

  MQ无法保证消息不被重复消费，只能由消费者来保证

  ##### 保证消费的时候是幂等的

  1. 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了， update 一下好吧。 
  2. 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
  3.  比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候， 里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id 去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
  4.  比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复 数据插入只会报错，不会导致数据库中出现脏数据。

  如何保证 MQ 的消费是幂等性的，需要结合具体的业务来看。

- #### 如何保证消息的可靠性传输？如果消息丢失了怎么办？

  ##### RabbitMQ

  - 生产者弄丢了数据
    - 事务机制（同步，性能低）
    - confirm机制 （异步）
  - MQ弄丢了数据
    - 数据落盘，开启持久化
  - 消费者弄丢了数据
    - 关闭自动ACK，处理完再ACK

  ##### Kafka

  - 生产者弄丢数据
    - 只要设置了`acks=all`就不可能丢失，必须得不断重试写入每个replica
  - Kafka弄丢数据
    - 给topic设置`replication.factor`参数，必须大于1，每个partition至少有两个副本
    - 给Kafka服务器端设置`min.insync.replicas`参数，必须大于1，每个leader至少感知到有一个follower和自己保持联系
    - 给producer端设置`acks=all`，每条数据必须是写入所有replica后才能认为写入成功
    - 给producer端设置`retries=MAX`，一旦写入失败，就无限重试
  - 消费者弄丢数据
    - 关闭自动提交offset

- #### 如何保证消息的顺序性？

  ##### RabbitMQ

  - 拆分队列，每一个队列对应一个消费者，有序消息进入同一个队列

  ##### Kafka

  - 到同一个内存队列

- #### 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？

  - 大量消息挤压
    - 原因预测：消费者挂了，或无法消费
    - 紧急扩容：
      1. 新建一个topic，partition是原来的十倍
      2. 写一个临时分发程序，把消息均匀轮询分发到十倍的partition
      3. 征用10倍的机器资源来部署comsumer

- #### 如果让你写一个消息队列，该如何进行架构设计啊？

  - 可伸缩性
  - 持久化
  - 高可用
  - 数据0丢失

## 搜索引擎

### ES分布式架构原理

#### Index -> Type -> mapping -> document -> field

#### Replica Shard

### ES写入数据的工作原理

#### 程序级别原理

write request -> coordinate node --router--> node(with primary shard) --synchronize--> replica node -> response

read request -> any node -> hashed doc id --router(load balanced with round robin)--> shard --response(to coodinate node)--> response

#### 操作系统级别原理

write request-> memory buffer --(full or a period of time)--> os cache (can be searched since here) -> segment file

translog

### 大数据场景下（数十亿级别）提升查询效率

1. 万变不离其中
   - 无脑加内存，把更多的内存留给filesystem cache
   - 把索引留在内存里，查到对应记录之后根据doc id去hbase/mysql读取完整数据
2. 数据预热
   - 写个程序把热点数据都刷到filesystem cache里
3. 冷热分离
4. 别用关联查询
5. 分页性能优化

## 缓存

### 项目中缓存是如何使用的

#### 高性能

#### 高并发

